{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainCheckpoint.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c6c1c1a8881447e9d9b57a7fe7ebb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d8d632c7a7e477ca816293e6d245a35",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c4f516d399c04c52a6fa6f0109bf1287",
              "IPY_MODEL_2282338823d04ebdbb35b3ff7bb1e859"
            ]
          }
        },
        "3d8d632c7a7e477ca816293e6d245a35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4f516d399c04c52a6fa6f0109bf1287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7d94136fd474f81b3c3a2cae4d5b631",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 532194478,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 532194478,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4aa2d33e988d46479131a258209c1b2b"
          }
        },
        "2282338823d04ebdbb35b3ff7bb1e859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dfb2a28a372a46b0a09de0d85a1b63bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 508M/508M [00:17&lt;00:00, 31.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26a1d2dfbc374da5b5b3c3c1d43d058d"
          }
        },
        "a7d94136fd474f81b3c3a2cae4d5b631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4aa2d33e988d46479131a258209c1b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfb2a28a372a46b0a09de0d85a1b63bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26a1d2dfbc374da5b5b3c3c1d43d058d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUR1woGHJY3T"
      },
      "source": [
        "# **Flower Image Classifier 2.0**\n",
        "\n",
        "In this Notebook I will train a State of the Art Densnet121 model on a dataset of flower images,<br>\n",
        "save the checkpoint, load it and attempt a prediction.\n",
        "<br>\n",
        "Later, this checkpoint is used for an application called\n",
        "<br>\n",
        "\"**What the Flower**\" that predicts the name of the flower appearing in an ueser-provided image\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Mount Google Drive**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WlllsHKN07C",
        "outputId": "51146ad9-8a08-4546-af17-b66b9e60945e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9zK7LXtJrXh"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWZVGg_hOKEQ"
      },
      "source": [
        "#conda install torchvision -c soumith\n",
        "\n",
        "import json\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from collections import OrderedDict\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOh-Q9J7Jx5Q"
      },
      "source": [
        "**Data**\n",
        "\n",
        "flowers dataset by: https://www.kaggle.com/immu0001/flowers\n",
        "<br>\n",
        "it is located inside my Google Drive, where the folder \"flowers\" is located in the exact same directory as \"trainCheckpoint.ipynb\".\n",
        "This database can easily be downloaded from Keggle, where all files can be extracted Winzip or 7Zip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl-k919JOVP1"
      },
      "source": [
        "#Paths to Data Directories\n",
        "test_dir = \"/content/drive/My Drive/Projects/wtFlower/flowers/test/\"\n",
        "train_dir = \"/content/drive/My Drive/Projects/wtFlower/flowers/train/\"\n",
        "valid_dir = \"/content/drive/My Drive/Projects/wtFlower/flowers/valid/\"\n",
        "\n",
        "#Data transforms\n",
        "data_transforms = {\n",
        "  'train': transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                               transforms.RandomRotation(0,360),\n",
        "                               transforms.RandomVerticalFlip(),\n",
        "                               transforms.RandomHorizontalFlip(),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "                                           ]),\n",
        "                   \n",
        "  'test': transforms.Compose([transforms.Resize(255),\n",
        "                              transforms.CenterCrop(224),\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "                      }\n",
        "\n",
        "# Loading datasets with ImageFolder\n",
        "image_datasets = {\n",
        "    'train': datasets.ImageFolder(train_dir, transform=data_transforms['train']),\n",
        "    'valid': datasets.ImageFolder(valid_dir, transform=data_transforms['test']),\n",
        "    'test': datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
        "    }\n",
        "\n",
        "# Define Dataloaders\n",
        "dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=64, shuffle=True),\n",
        "    'valid': torch.utils.data.DataLoader(image_datasets['valid'], batch_size=64),\n",
        "    'test': torch.utils.data.DataLoader(image_datasets['test'], batch_size=32)\n",
        "    }"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI6QEIbHKPEY"
      },
      "source": [
        "**Load a State of the art Neural Network**\n",
        "\n",
        "loading Vgg13 and printing its architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740,
          "referenced_widgets": [
            "2c6c1c1a8881447e9d9b57a7fe7ebb40",
            "3d8d632c7a7e477ca816293e6d245a35",
            "c4f516d399c04c52a6fa6f0109bf1287",
            "2282338823d04ebdbb35b3ff7bb1e859",
            "a7d94136fd474f81b3c3a2cae4d5b631",
            "4aa2d33e988d46479131a258209c1b2b",
            "dfb2a28a372a46b0a09de0d85a1b63bb",
            "26a1d2dfbc374da5b5b3c3c1d43d058d"
          ]
        },
        "id": "aIq20xRuOuzW",
        "outputId": "e007f763-c365-49c5-9095-5bc41a97951b"
      },
      "source": [
        "model = models.vgg13(pretrained=True)\n",
        "input_units = model.classifier[0].in_features\n",
        "\n",
        "model"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg13-c768596a.pth\" to /root/.cache/torch/hub/checkpoints/vgg13-c768596a.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c6c1c1a8881447e9d9b57a7fe7ebb40",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=532194478.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): ReLU(inplace=True)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): ReLU(inplace=True)\n",
              "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxzwNHjAKrMu"
      },
      "source": [
        "**Set Classifier**\n",
        "<br>\n",
        "modifing the classifier function of the model\n",
        "<br>\n",
        "adjusting to 102 outputs (as the number of categories in cat_to_name)\n",
        "<br>\n",
        "and setting parameters hidden layers, epochs, learing rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E2LwsvPO3S3",
        "outputId": "1790115b-34d7-4f1c-f0ca-dca307abb8d3"
      },
      "source": [
        "#Hyperparameters\n",
        "learning_rate = 0.001\n",
        "hidden_units = 512\n",
        "epochs = 16\n",
        "\n",
        "#Freeze parameters for backpropogation\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "#create a new classifier function\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                      ('fc1', nn.Linear(input_units, hidden_units)),\n",
        "                      ('relu', nn.ReLU()),\n",
        "                      ('dropout', nn.Dropout(p=0.5)),\n",
        "                      ('fc2', nn.Linear(hidden_units, 102)),\n",
        "                      ('output', nn.LogSoftmax(dim=1))\n",
        "                      ]))\n",
        "#update classifier\n",
        "model.classifier = classifier  \n",
        "model "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): ReLU(inplace=True)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): ReLU(inplace=True)\n",
              "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (fc1): Linear(in_features=25088, out_features=512, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (fc2): Linear(in_features=512, out_features=102, bias=True)\n",
              "    (output): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUFOVGDqPKyK"
      },
      "source": [
        "#Training Begins\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "#Define itteration variables\n",
        "print_every = 10\n",
        "steps = 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPWh4JMHPzf-",
        "outputId": "18decc00-0633-4311-9542-23f27d46a82e"
      },
      "source": [
        "#Validation Function\n",
        "def validation(model, testloader, criterion):\n",
        "    #Define validation variables\n",
        "    validation_loss = 0\n",
        "    validation_accuracy = 0\n",
        "    #Itterare over the validation set\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model.forward(images)\n",
        "        validation_loss += criterion(output, labels).item()\n",
        "        ps = torch.exp(output)\n",
        "        equality = (labels.data == ps.max(dim=1)[1])\n",
        "        validation_accuracy += equality.type(torch.FloatTensor).mean()  \n",
        "    return validation_loss, validation_accuracy\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print('GPU Enabled, training on GPU...')\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print('no GPU, training on CPU...')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "val_loss = []\n",
        "val_accuracy = []\n",
        "train_loss = []\n",
        "\n",
        "#Start training the model\n",
        "for e in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    #Itterare over the training set\n",
        "    for ii, (inputs, labels) in enumerate(dataloaders['train']):\n",
        "        steps += 1\n",
        "        inputs, labels = inputs.to(device), labels.to(device)        \n",
        "        optimizer.zero_grad()      \n",
        "        # Forward and backward passes\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        running_loss += loss.item()\n",
        "    \n",
        "        #Model Progress\n",
        "        if steps % print_every == 0:\n",
        "            #Model in evaluation\n",
        "            model.eval()            \n",
        "            # Turn off gradients for validation\n",
        "            with torch.no_grad():\n",
        "                validation_loss, validation_accuracy = validation(model, dataloaders['valid'], criterion)\n",
        "            #Printing Training + Validation information    \n",
        "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "                  \"Validation Loss: {:.3f}.. \".format(validation_loss/len(dataloaders['valid'])),\n",
        "                  \"Validation Accuracy: {:.3f}\".format(validation_accuracy/len(dataloaders['valid'])))  \n",
        "            val_loss.append(validation_loss)\n",
        "            train_loss.append(running_loss/print_every)  \n",
        "            val_accuracy.append(validation_accuracy/len(dataloaders['valid']))\n",
        "            running_loss = 0\n",
        "        \n",
        "        # Model back to training\n",
        "        model.train()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Enabled, training on GPU...\n",
            "Epoch: 1/16..  Training Loss: 5.224..  Validation Loss: 3.824..  Validation Accuracy: 0.190\n",
            "Epoch: 1/16..  Training Loss: 4.076..  Validation Loss: 3.419..  Validation Accuracy: 0.273\n",
            "Epoch: 1/16..  Training Loss: 3.762..  Validation Loss: 2.879..  Validation Accuracy: 0.363\n",
            "Epoch: 1/16..  Training Loss: 3.333..  Validation Loss: 2.503..  Validation Accuracy: 0.443\n",
            "Epoch: 1/16..  Training Loss: 2.937..  Validation Loss: 2.077..  Validation Accuracy: 0.507\n",
            "Epoch: 1/16..  Training Loss: 2.960..  Validation Loss: 1.854..  Validation Accuracy: 0.557\n",
            "Epoch: 1/16..  Training Loss: 2.568..  Validation Loss: 1.584..  Validation Accuracy: 0.628\n",
            "Epoch: 1/16..  Training Loss: 2.400..  Validation Loss: 1.398..  Validation Accuracy: 0.643\n",
            "Epoch: 1/16..  Training Loss: 2.329..  Validation Loss: 1.304..  Validation Accuracy: 0.676\n",
            "Epoch: 1/16..  Training Loss: 2.329..  Validation Loss: 1.170..  Validation Accuracy: 0.708\n",
            "Epoch: 2/16..  Training Loss: 1.473..  Validation Loss: 1.041..  Validation Accuracy: 0.737\n",
            "Epoch: 2/16..  Training Loss: 2.020..  Validation Loss: 0.992..  Validation Accuracy: 0.757\n",
            "Epoch: 2/16..  Training Loss: 1.948..  Validation Loss: 0.897..  Validation Accuracy: 0.779\n",
            "Epoch: 2/16..  Training Loss: 1.981..  Validation Loss: 0.890..  Validation Accuracy: 0.768\n",
            "Epoch: 2/16..  Training Loss: 1.757..  Validation Loss: 0.861..  Validation Accuracy: 0.767\n",
            "Epoch: 2/16..  Training Loss: 1.843..  Validation Loss: 0.860..  Validation Accuracy: 0.771\n",
            "Epoch: 2/16..  Training Loss: 1.839..  Validation Loss: 0.799..  Validation Accuracy: 0.804\n",
            "Epoch: 2/16..  Training Loss: 1.698..  Validation Loss: 0.800..  Validation Accuracy: 0.793\n",
            "Epoch: 2/16..  Training Loss: 1.728..  Validation Loss: 0.694..  Validation Accuracy: 0.823\n",
            "Epoch: 2/16..  Training Loss: 1.642..  Validation Loss: 0.732..  Validation Accuracy: 0.809\n",
            "Epoch: 3/16..  Training Loss: 0.662..  Validation Loss: 0.783..  Validation Accuracy: 0.786\n",
            "Epoch: 3/16..  Training Loss: 1.597..  Validation Loss: 0.755..  Validation Accuracy: 0.801\n",
            "Epoch: 3/16..  Training Loss: 1.542..  Validation Loss: 0.699..  Validation Accuracy: 0.819\n",
            "Epoch: 3/16..  Training Loss: 1.385..  Validation Loss: 0.698..  Validation Accuracy: 0.815\n",
            "Epoch: 3/16..  Training Loss: 1.395..  Validation Loss: 0.662..  Validation Accuracy: 0.819\n",
            "Epoch: 3/16..  Training Loss: 1.803..  Validation Loss: 0.664..  Validation Accuracy: 0.834\n",
            "Epoch: 3/16..  Training Loss: 1.413..  Validation Loss: 0.669..  Validation Accuracy: 0.821\n",
            "Epoch: 3/16..  Training Loss: 1.491..  Validation Loss: 0.647..  Validation Accuracy: 0.826\n",
            "Epoch: 3/16..  Training Loss: 1.509..  Validation Loss: 0.637..  Validation Accuracy: 0.828\n",
            "Epoch: 3/16..  Training Loss: 1.532..  Validation Loss: 0.596..  Validation Accuracy: 0.838\n",
            "Epoch: 4/16..  Training Loss: 0.135..  Validation Loss: 0.597..  Validation Accuracy: 0.844\n",
            "Epoch: 4/16..  Training Loss: 1.403..  Validation Loss: 0.585..  Validation Accuracy: 0.839\n",
            "Epoch: 4/16..  Training Loss: 1.361..  Validation Loss: 0.579..  Validation Accuracy: 0.833\n",
            "Epoch: 4/16..  Training Loss: 1.440..  Validation Loss: 0.583..  Validation Accuracy: 0.851\n",
            "Epoch: 4/16..  Training Loss: 1.321..  Validation Loss: 0.578..  Validation Accuracy: 0.864\n",
            "Epoch: 4/16..  Training Loss: 1.447..  Validation Loss: 0.586..  Validation Accuracy: 0.869\n",
            "Epoch: 4/16..  Training Loss: 1.337..  Validation Loss: 0.600..  Validation Accuracy: 0.850\n",
            "Epoch: 4/16..  Training Loss: 1.359..  Validation Loss: 0.565..  Validation Accuracy: 0.858\n",
            "Epoch: 4/16..  Training Loss: 1.481..  Validation Loss: 0.563..  Validation Accuracy: 0.853\n",
            "Epoch: 4/16..  Training Loss: 1.248..  Validation Loss: 0.567..  Validation Accuracy: 0.859\n",
            "Epoch: 4/16..  Training Loss: 1.442..  Validation Loss: 0.569..  Validation Accuracy: 0.849\n",
            "Epoch: 5/16..  Training Loss: 1.175..  Validation Loss: 0.581..  Validation Accuracy: 0.840\n",
            "Epoch: 5/16..  Training Loss: 1.182..  Validation Loss: 0.545..  Validation Accuracy: 0.863\n",
            "Epoch: 5/16..  Training Loss: 1.167..  Validation Loss: 0.552..  Validation Accuracy: 0.851\n",
            "Epoch: 5/16..  Training Loss: 1.200..  Validation Loss: 0.521..  Validation Accuracy: 0.866\n",
            "Epoch: 5/16..  Training Loss: 1.349..  Validation Loss: 0.519..  Validation Accuracy: 0.869\n",
            "Epoch: 5/16..  Training Loss: 1.287..  Validation Loss: 0.505..  Validation Accuracy: 0.874\n",
            "Epoch: 5/16..  Training Loss: 1.248..  Validation Loss: 0.473..  Validation Accuracy: 0.880\n",
            "Epoch: 5/16..  Training Loss: 1.174..  Validation Loss: 0.489..  Validation Accuracy: 0.874\n",
            "Epoch: 5/16..  Training Loss: 1.188..  Validation Loss: 0.498..  Validation Accuracy: 0.862\n",
            "Epoch: 6/16..  Training Loss: 0.696..  Validation Loss: 0.509..  Validation Accuracy: 0.864\n",
            "Epoch: 6/16..  Training Loss: 1.131..  Validation Loss: 0.518..  Validation Accuracy: 0.871\n",
            "Epoch: 6/16..  Training Loss: 1.305..  Validation Loss: 0.504..  Validation Accuracy: 0.872\n",
            "Epoch: 6/16..  Training Loss: 1.275..  Validation Loss: 0.506..  Validation Accuracy: 0.866\n",
            "Epoch: 6/16..  Training Loss: 1.208..  Validation Loss: 0.509..  Validation Accuracy: 0.874\n",
            "Epoch: 6/16..  Training Loss: 1.241..  Validation Loss: 0.512..  Validation Accuracy: 0.862\n",
            "Epoch: 6/16..  Training Loss: 1.239..  Validation Loss: 0.510..  Validation Accuracy: 0.863\n",
            "Epoch: 6/16..  Training Loss: 1.088..  Validation Loss: 0.505..  Validation Accuracy: 0.869\n",
            "Epoch: 6/16..  Training Loss: 1.077..  Validation Loss: 0.488..  Validation Accuracy: 0.874\n",
            "Epoch: 6/16..  Training Loss: 1.311..  Validation Loss: 0.499..  Validation Accuracy: 0.874\n",
            "Epoch: 7/16..  Training Loss: 0.189..  Validation Loss: 0.504..  Validation Accuracy: 0.854\n",
            "Epoch: 7/16..  Training Loss: 1.138..  Validation Loss: 0.502..  Validation Accuracy: 0.866\n",
            "Epoch: 7/16..  Training Loss: 1.088..  Validation Loss: 0.528..  Validation Accuracy: 0.860\n",
            "Epoch: 7/16..  Training Loss: 1.193..  Validation Loss: 0.559..  Validation Accuracy: 0.855\n",
            "Epoch: 7/16..  Training Loss: 1.039..  Validation Loss: 0.514..  Validation Accuracy: 0.863\n",
            "Epoch: 7/16..  Training Loss: 1.189..  Validation Loss: 0.502..  Validation Accuracy: 0.871\n",
            "Epoch: 7/16..  Training Loss: 1.187..  Validation Loss: 0.496..  Validation Accuracy: 0.875\n",
            "Epoch: 7/16..  Training Loss: 1.121..  Validation Loss: 0.521..  Validation Accuracy: 0.876\n",
            "Epoch: 7/16..  Training Loss: 1.114..  Validation Loss: 0.477..  Validation Accuracy: 0.884\n",
            "Epoch: 7/16..  Training Loss: 1.272..  Validation Loss: 0.505..  Validation Accuracy: 0.863\n",
            "Epoch: 7/16..  Training Loss: 1.166..  Validation Loss: 0.515..  Validation Accuracy: 0.857\n",
            "Epoch: 8/16..  Training Loss: 1.011..  Validation Loss: 0.494..  Validation Accuracy: 0.878\n",
            "Epoch: 8/16..  Training Loss: 1.112..  Validation Loss: 0.494..  Validation Accuracy: 0.884\n",
            "Epoch: 8/16..  Training Loss: 1.138..  Validation Loss: 0.513..  Validation Accuracy: 0.864\n",
            "Epoch: 8/16..  Training Loss: 1.164..  Validation Loss: 0.509..  Validation Accuracy: 0.873\n",
            "Epoch: 8/16..  Training Loss: 1.221..  Validation Loss: 0.509..  Validation Accuracy: 0.879\n",
            "Epoch: 8/16..  Training Loss: 1.188..  Validation Loss: 0.472..  Validation Accuracy: 0.877\n",
            "Epoch: 8/16..  Training Loss: 0.952..  Validation Loss: 0.458..  Validation Accuracy: 0.875\n",
            "Epoch: 8/16..  Training Loss: 1.107..  Validation Loss: 0.468..  Validation Accuracy: 0.880\n",
            "Epoch: 8/16..  Training Loss: 1.194..  Validation Loss: 0.474..  Validation Accuracy: 0.872\n",
            "Epoch: 8/16..  Training Loss: 1.148..  Validation Loss: 0.461..  Validation Accuracy: 0.883\n",
            "Epoch: 9/16..  Training Loss: 0.921..  Validation Loss: 0.481..  Validation Accuracy: 0.872\n",
            "Epoch: 9/16..  Training Loss: 1.094..  Validation Loss: 0.461..  Validation Accuracy: 0.881\n",
            "Epoch: 9/16..  Training Loss: 1.209..  Validation Loss: 0.466..  Validation Accuracy: 0.880\n",
            "Epoch: 9/16..  Training Loss: 1.149..  Validation Loss: 0.470..  Validation Accuracy: 0.881\n",
            "Epoch: 9/16..  Training Loss: 1.079..  Validation Loss: 0.511..  Validation Accuracy: 0.863\n",
            "Epoch: 9/16..  Training Loss: 1.108..  Validation Loss: 0.475..  Validation Accuracy: 0.873\n",
            "Epoch: 9/16..  Training Loss: 1.071..  Validation Loss: 0.499..  Validation Accuracy: 0.875\n",
            "Epoch: 9/16..  Training Loss: 1.090..  Validation Loss: 0.477..  Validation Accuracy: 0.882\n",
            "Epoch: 9/16..  Training Loss: 1.136..  Validation Loss: 0.479..  Validation Accuracy: 0.867\n",
            "Epoch: 9/16..  Training Loss: 1.226..  Validation Loss: 0.469..  Validation Accuracy: 0.873\n",
            "Epoch: 10/16..  Training Loss: 0.352..  Validation Loss: 0.468..  Validation Accuracy: 0.871\n",
            "Epoch: 10/16..  Training Loss: 1.076..  Validation Loss: 0.482..  Validation Accuracy: 0.862\n",
            "Epoch: 10/16..  Training Loss: 1.196..  Validation Loss: 0.474..  Validation Accuracy: 0.879\n",
            "Epoch: 10/16..  Training Loss: 1.073..  Validation Loss: 0.488..  Validation Accuracy: 0.874\n",
            "Epoch: 10/16..  Training Loss: 0.968..  Validation Loss: 0.492..  Validation Accuracy: 0.874\n",
            "Epoch: 10/16..  Training Loss: 1.024..  Validation Loss: 0.450..  Validation Accuracy: 0.886\n",
            "Epoch: 10/16..  Training Loss: 1.082..  Validation Loss: 0.447..  Validation Accuracy: 0.888\n",
            "Epoch: 10/16..  Training Loss: 1.026..  Validation Loss: 0.508..  Validation Accuracy: 0.871\n",
            "Epoch: 10/16..  Training Loss: 1.115..  Validation Loss: 0.476..  Validation Accuracy: 0.870\n",
            "Epoch: 10/16..  Training Loss: 1.176..  Validation Loss: 0.436..  Validation Accuracy: 0.885\n",
            "Epoch: 10/16..  Training Loss: 1.178..  Validation Loss: 0.455..  Validation Accuracy: 0.888\n",
            "Epoch: 11/16..  Training Loss: 1.150..  Validation Loss: 0.428..  Validation Accuracy: 0.893\n",
            "Epoch: 11/16..  Training Loss: 1.119..  Validation Loss: 0.442..  Validation Accuracy: 0.886\n",
            "Epoch: 11/16..  Training Loss: 0.980..  Validation Loss: 0.487..  Validation Accuracy: 0.880\n",
            "Epoch: 11/16..  Training Loss: 1.066..  Validation Loss: 0.492..  Validation Accuracy: 0.875\n",
            "Epoch: 11/16..  Training Loss: 1.094..  Validation Loss: 0.490..  Validation Accuracy: 0.871\n",
            "Epoch: 11/16..  Training Loss: 0.987..  Validation Loss: 0.452..  Validation Accuracy: 0.880\n",
            "Epoch: 11/16..  Training Loss: 1.128..  Validation Loss: 0.457..  Validation Accuracy: 0.886\n",
            "Epoch: 11/16..  Training Loss: 1.060..  Validation Loss: 0.468..  Validation Accuracy: 0.893\n",
            "Epoch: 11/16..  Training Loss: 1.134..  Validation Loss: 0.462..  Validation Accuracy: 0.885\n",
            "Epoch: 11/16..  Training Loss: 1.071..  Validation Loss: 0.463..  Validation Accuracy: 0.882\n",
            "Epoch: 12/16..  Training Loss: 0.734..  Validation Loss: 0.452..  Validation Accuracy: 0.889\n",
            "Epoch: 12/16..  Training Loss: 1.048..  Validation Loss: 0.462..  Validation Accuracy: 0.883\n",
            "Epoch: 12/16..  Training Loss: 1.075..  Validation Loss: 0.468..  Validation Accuracy: 0.888\n",
            "Epoch: 12/16..  Training Loss: 1.164..  Validation Loss: 0.450..  Validation Accuracy: 0.882\n",
            "Epoch: 12/16..  Training Loss: 1.027..  Validation Loss: 0.450..  Validation Accuracy: 0.882\n",
            "Epoch: 12/16..  Training Loss: 1.228..  Validation Loss: 0.444..  Validation Accuracy: 0.884\n",
            "Epoch: 12/16..  Training Loss: 0.963..  Validation Loss: 0.440..  Validation Accuracy: 0.889\n",
            "Epoch: 12/16..  Training Loss: 1.000..  Validation Loss: 0.445..  Validation Accuracy: 0.893\n",
            "Epoch: 12/16..  Training Loss: 1.049..  Validation Loss: 0.456..  Validation Accuracy: 0.896\n",
            "Epoch: 12/16..  Training Loss: 1.170..  Validation Loss: 0.438..  Validation Accuracy: 0.893\n",
            "Epoch: 13/16..  Training Loss: 0.449..  Validation Loss: 0.455..  Validation Accuracy: 0.886\n",
            "Epoch: 13/16..  Training Loss: 1.025..  Validation Loss: 0.450..  Validation Accuracy: 0.883\n",
            "Epoch: 13/16..  Training Loss: 0.859..  Validation Loss: 0.459..  Validation Accuracy: 0.887\n",
            "Epoch: 13/16..  Training Loss: 0.925..  Validation Loss: 0.457..  Validation Accuracy: 0.890\n",
            "Epoch: 13/16..  Training Loss: 1.151..  Validation Loss: 0.439..  Validation Accuracy: 0.891\n",
            "Epoch: 13/16..  Training Loss: 1.067..  Validation Loss: 0.473..  Validation Accuracy: 0.880\n",
            "Epoch: 13/16..  Training Loss: 1.080..  Validation Loss: 0.467..  Validation Accuracy: 0.885\n",
            "Epoch: 13/16..  Training Loss: 0.983..  Validation Loss: 0.488..  Validation Accuracy: 0.887\n",
            "Epoch: 13/16..  Training Loss: 0.894..  Validation Loss: 0.487..  Validation Accuracy: 0.889\n",
            "Epoch: 13/16..  Training Loss: 1.093..  Validation Loss: 0.461..  Validation Accuracy: 0.892\n",
            "Epoch: 14/16..  Training Loss: 0.138..  Validation Loss: 0.485..  Validation Accuracy: 0.875\n",
            "Epoch: 14/16..  Training Loss: 0.985..  Validation Loss: 0.485..  Validation Accuracy: 0.883\n",
            "Epoch: 14/16..  Training Loss: 1.088..  Validation Loss: 0.437..  Validation Accuracy: 0.887\n",
            "Epoch: 14/16..  Training Loss: 1.084..  Validation Loss: 0.433..  Validation Accuracy: 0.894\n",
            "Epoch: 14/16..  Training Loss: 1.021..  Validation Loss: 0.431..  Validation Accuracy: 0.896\n",
            "Epoch: 14/16..  Training Loss: 0.960..  Validation Loss: 0.429..  Validation Accuracy: 0.898\n",
            "Epoch: 14/16..  Training Loss: 1.011..  Validation Loss: 0.437..  Validation Accuracy: 0.894\n",
            "Epoch: 14/16..  Training Loss: 0.990..  Validation Loss: 0.429..  Validation Accuracy: 0.897\n",
            "Epoch: 14/16..  Training Loss: 1.020..  Validation Loss: 0.436..  Validation Accuracy: 0.897\n",
            "Epoch: 14/16..  Training Loss: 1.152..  Validation Loss: 0.411..  Validation Accuracy: 0.899\n",
            "Epoch: 14/16..  Training Loss: 1.040..  Validation Loss: 0.446..  Validation Accuracy: 0.883\n",
            "Epoch: 15/16..  Training Loss: 0.951..  Validation Loss: 0.449..  Validation Accuracy: 0.888\n",
            "Epoch: 15/16..  Training Loss: 1.069..  Validation Loss: 0.454..  Validation Accuracy: 0.893\n",
            "Epoch: 15/16..  Training Loss: 0.907..  Validation Loss: 0.453..  Validation Accuracy: 0.895\n",
            "Epoch: 15/16..  Training Loss: 1.051..  Validation Loss: 0.420..  Validation Accuracy: 0.905\n",
            "Epoch: 15/16..  Training Loss: 1.136..  Validation Loss: 0.433..  Validation Accuracy: 0.887\n",
            "Epoch: 15/16..  Training Loss: 1.180..  Validation Loss: 0.469..  Validation Accuracy: 0.878\n",
            "Epoch: 15/16..  Training Loss: 1.039..  Validation Loss: 0.456..  Validation Accuracy: 0.883\n",
            "Epoch: 15/16..  Training Loss: 1.027..  Validation Loss: 0.440..  Validation Accuracy: 0.890\n",
            "Epoch: 15/16..  Training Loss: 1.114..  Validation Loss: 0.444..  Validation Accuracy: 0.893\n",
            "Epoch: 15/16..  Training Loss: 1.125..  Validation Loss: 0.451..  Validation Accuracy: 0.883\n",
            "Epoch: 16/16..  Training Loss: 0.578..  Validation Loss: 0.429..  Validation Accuracy: 0.894\n",
            "Epoch: 16/16..  Training Loss: 1.003..  Validation Loss: 0.444..  Validation Accuracy: 0.889\n",
            "Epoch: 16/16..  Training Loss: 1.010..  Validation Loss: 0.431..  Validation Accuracy: 0.893\n",
            "Epoch: 16/16..  Training Loss: 0.980..  Validation Loss: 0.432..  Validation Accuracy: 0.892\n",
            "Epoch: 16/16..  Training Loss: 1.108..  Validation Loss: 0.441..  Validation Accuracy: 0.884\n",
            "Epoch: 16/16..  Training Loss: 1.088..  Validation Loss: 0.443..  Validation Accuracy: 0.903\n",
            "Epoch: 16/16..  Training Loss: 1.097..  Validation Loss: 0.412..  Validation Accuracy: 0.903\n",
            "Epoch: 16/16..  Training Loss: 0.917..  Validation Loss: 0.407..  Validation Accuracy: 0.899\n",
            "Epoch: 16/16..  Training Loss: 0.948..  Validation Loss: 0.413..  Validation Accuracy: 0.899\n",
            "Epoch: 16/16..  Training Loss: 0.998..  Validation Loss: 0.425..  Validation Accuracy: 0.893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7-xuCmBQYtJ",
        "outputId": "3b028f15-a89e-4e58-a3af-210f7394582f"
      },
      "source": [
        "#Validation on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "#Itterare over the test set\n",
        "with torch.no_grad():\n",
        "    for data in dataloaders['test']:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 77 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukKLrAKyRoF_"
      },
      "source": [
        "# **Functions**\n",
        "1. Save Checkpoint\n",
        "<br>\n",
        "2. Load Checkpoint\n",
        "<br>\n",
        "3. Predict Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyVbSK4UYk3J"
      },
      "source": [
        "#Save Checkpoint\n",
        "checkpoint = {'model': model,\n",
        "              'state_dict': model.state_dict(),\n",
        "              'class_to_idx': image_datasets['train'].class_to_idx,\n",
        "              'epochs': epochs,\n",
        "              'print_every': print_every,\n",
        "              'val_accuracy': val_accuracy,\n",
        "              'train_loss': train_loss,\n",
        "              'val_loss': val_loss,\n",
        "              'optimizer_state': optimizer.state_dict()}\n",
        "\n",
        "#Load Checkpoint              \n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model.class_to_idx = checkpoint['class_to_idx']\n",
        "    model.epochs = checkpoint['epochs']\n",
        "    model.print_every = checkpoint['print_every']\n",
        "    model.val_accuracy = checkpoint['val_accuracy']\n",
        "    model.train_loss = checkpoint['train_loss']\n",
        "    model.val_loss = checkpoint['val_loss']\n",
        "    model.optimizer_state = checkpoint['optimizer_state']\n",
        "    return model\n",
        "\n",
        "#Prediction Function\n",
        "def predict(image_path, model, topk=3): \n",
        "    '''returns the top kk probabilities & classes for given image based on user input & model architecture'''\n",
        "    image_tensor = torch.from_numpy(image_path)\n",
        "    image_tensor = np.transpose(image_tensor, (2,0,1))\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    image_tensor = image_tensor.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model.double().forward(image_tensor)\n",
        "    #receive probabilities as 0 - 1 floats with exp\n",
        "    ps = torch.exp(output)\n",
        "    topk_combined = ps.topk(top_k, sorted=True)\n",
        "    #top kk probabilities\n",
        "    topk_ps = topk_combined[0][0]\n",
        "    #top kk classes\n",
        "    topk_cs = topk_combined[1][0]\n",
        "    return topk_ps, topk_cs  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WufYrsmSGXk"
      },
      "source": [
        "**Save Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTK5nCoVSEDf"
      },
      "source": [
        "torch.save(checkpoint, os.path.join('/content/drive/My Drive/Projects/wtFlower/','checkpoint1.pth'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH5bful7RNIb"
      },
      "source": [
        "# **Prediction**\n",
        "Load Checkpoint, load name to index mapping, plot loss, make a prediction on a demo image never seen before by the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUIIB9_XSc8j"
      },
      "source": [
        "#Loading trained model for prediction\n",
        "model = load_checkpoint('/content/drive/My Drive/Projects/wtFlower/checkpoint1.pth')\n",
        "\n",
        "#Category to name user argument defaults to 'cat_to_name.json'\n",
        "json_file = '/content/drive/My Drive/Projects/wtFlower/cat_to_name.json'\n",
        "with open(json_file, 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goFOXUjAWTcl"
      },
      "source": [
        "**Plot Training Loss vs Validation Loss**\n",
        "<br>\n",
        "to ensure the model doesn't overfilt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "RpL9SFeqWZYP",
        "outputId": "81aed105-31fe-4e20-9282-7d3adb1393ee"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "d = {'validation loss': model.val_loss, 'train loss': model.train_loss}\n",
        "data = pd.DataFrame(data=d)\n",
        "\n",
        "data.plot(kind='line')\n",
        "print('N loss values', len(model.train_loss), len(model.val_loss))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N loss values 164 164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXzU1b3/8dfJLJnse0I2CPsSdgJGIyLiAnjd11YrWluv1la72Fva3tr23tqrrT+vtdeltGrRahVR1LrUKgWRKsgi+xb2LJB93ydzfn+cSQgYIIRkJt+Zz/PxyCOzfz9zZub9Pd/z3ZTWGiGEENYT4u8ChBBC9I4EuBBCWJQEuBBCWJQEuBBCWJQEuBBCWJTdlxNLTEzUWVlZvpykEEJY3oYNG8q11kkn3u7TAM/KymL9+vW+nKQQQlieUupQd7fLEIoQQliUBLgQQliUBLgQQliUT8fAhRC+19bWRmFhIc3Nzf4uRZyGy+UiIyMDh8PRo8f3KMCVUgeBOqAdcGutc5RS8cCrQBZwELhRa13Vi5qFEP2osLCQqKgosrKyUEr5uxxxElprKioqKCwsZOjQoT16zpkMoczWWk/WWud4ry8ElmutRwLLvdeFEANMc3MzCQkJEt4DnFKKhISEM1pSOpsx8KuAxd7Li4Grz+K1hBD9SMLbGs70c+ppgGvgH0qpDUqpu7y3pWitj3gvHwVSTlLQXUqp9Uqp9WVlZWdUXIdlXxTylzXdbgYphBBBq6cBfr7WeiowD7hXKXVB1zu1Oah4twcW11ov0lrnaK1zkpK+tCNRj7y75agEuBBBJDIyEoDi4mKuv/76bh9z4YUXnnbHwMcff5zGxsbO6/Pnz6e6uvqs6/vFL37Bo48+etavc7Z6FOBa6yLv/1JgGTADKFFKpQJ4/5f2V5FJUU7K61v76+WFEANUWloaS5cu7fXzTwzw9957j9jY2L4obUA4bYArpSKUUlEdl4FLgW3A28AC78MWAG/1V5GJkaFUNrTQ7pGzBwlhNQsXLuTJJ5/svN7Re62vr2fOnDlMnTqVCRMm8NZbX46QgwcPMn78eACampq4+eabGTt2LNdccw1NTU2dj7vnnnvIyckhOzubn//85wA88cQTFBcXM3v2bGbPng2Yw3mUl5cD8NhjjzF+/HjGjx/P448/3jm9sWPH8s1vfpPs7GwuvfTS46bTnU2bNpGbm8vEiRO55pprqKqq6pz+uHHjmDhxIjfffDMAH3/8MZMnT2by5MlMmTKFurq6XrVph55sRpgCLPMOrtuBl7XWf1dKrQOWKKXuBA4BN55VJaeQGBmKR0NVYyuJkaH9NRkhAt4v/7adHcW1ffqa49Ki+fkV2Se9/6abbuK73/0u9957LwBLlizhgw8+wOVysWzZMqKjoykvLyc3N5crr7zypCvynn76acLDw9m5cydbtmxh6tSpnfc99NBDxMfH097ezpw5c9iyZQv33Xcfjz32GCtWrCAxMfG419qwYQPPP/88a9euRWvNOeecw6xZs4iLiyM/P5+//vWv/PGPf+TGG2/k9ddf59Zbbz3p+7vtttv4/e9/z6xZs3jwwQf55S9/yeOPP87DDz/MgQMHCA0N7Ry2efTRR3nyySfJy8ujvr4el8vV43buzml74Frr/VrrSd6/bK31Q97bK7TWc7TWI7XWF2utK8+qklNIiHQCUCHDKEJYzpQpUygtLaW4uJjNmzcTFxdHZmYmWmt+8pOfMHHiRC6++GKKioooKSk56eusWrWqM0gnTpzIxIkTO+9bsmQJU6dOZcqUKWzfvp0dO3acsqbVq1dzzTXXEBERQWRkJNdeey2ffPIJAEOHDmXy5MkATJs2jYMHD570dWpqaqiurmbWrFkALFiwgFWrVnXWeMstt/CXv/wFu930lfPy8vj+97/PE088QXV1deftvWWJPTE7et3l9S2MJsrP1QhhXafqKfenG264gaVLl3L06FFuuukmAF566SXKysrYsGEDDoeDrKysXu0teuDAAR599FHWrVtHXFwct99++1ntdRoaemwp32aznXYI5WTeffddVq1axd/+9jceeughtm7dysKFC7n88st57733yMvL44MPPmDMmDG9rtUSx0LpGuBCCOu56aabeOWVV1i6dCk33HADYHqvycnJOBwOVqxYwaFDp97S7IILLuDll18GYNu2bWzZsgWA2tpaIiIiiImJoaSkhPfff7/zOVFRUd2OM8+cOZM333yTxsZGGhoaWLZsGTNnzjzj9xUTE0NcXFxn7/3FF19k1qxZeDweCgoKmD17No888gg1NTXU19ezb98+JkyYwI9+9COmT5/Orl27zniaXVmiB57kDfCyOglwIawoOzuburo60tPTSU1NBeCWW27hiiuuYMKECeTk5Jy2J3rPPfdwxx13MHbsWMaOHcu0adMAmDRpElOmTGHMmDFkZmaSl5fX+Zy77rqLuXPnkpaWxooVKzpvnzp1KrfffjszZswA4Bvf+AZTpkw55XDJySxevJi7776bxsZGhg0bxvPPP097ezu33norNTU1aK257777iI2N5Wc/+xkrVqwgJCSE7Oxs5s2bd8bT60qZTbh9IycnR/fmhA5aa0b95/vcef4wFs7r/eKGEMFo586djB071t9liB7q7vNSSm3ochiTTpYYQlFKkRARSoUMoQghRCdLBDhAYpRTxsCFEKIL6wR4ZKjsjSmEEF1YLMClBy6EEB0sE+AJkU4q6lvx5UpXIYQYyCwT4EmRobS2e6htdvu7FCGEGBAsE+CyM48Q1lRdXc1TTz3Vq+ee6eFfB8phXn3FegEuO/MIYSmnCnC3+9RL1IF2+Ne+ZpkA7ziglWyJIoS1LFy4kH379jF58mR++MMfsnLlSmbOnMmVV17JuHHjALj66quZNm0a2dnZLFq0qPO5HYd/tdphXn3FErvSw7EeeEWD9MCF6LX3F8LRrX37moMmwLyHT3r3ww8/zLZt29i0aRMAK1euZOPGjWzbtq3z7OvPPfcc8fHxNDU1MX36dK677joSEhKOex0rHebVVyzTA4+PcBKiZAhFiEAwY8aMzvAG0yueNGkSubm5FBQUkJ+f/6XnWOkwr75ijSoBW4giPsJJmQyhCNF7p+gp+1JERETn5ZUrV/LRRx/x2WefER4ezoUXXtjt4WCtdJhXX7FMDxxML7xShlCEsJSTHdK1Q01NDXFxcYSHh7Nr1y7WrFlz1tP092FefcUyPXCAmDAHNU1t/i5DCHEGEhISyMvLY/z48cybN4/LL7/8uPvnzp3LM888w9ixYxk9ejS5ubl9Ml1/HubVVyxxONkO31i8jqLqZt6//8wPvC5EsJLDyVpLwB1OtkNMmJNa6YELIQRguQCXIRQhhOhguQCvb3HT1u7xdylCWIocBM4azvRzsliAm3WuMowiRM+5XC4qKiokxAc4rTUVFRVntBORtbZCCXcAUNPURkJk6GkeLYQAyMjIoLCwkLKyMn+XIk7D5XKRkZHR48dbK8DDjgW4EKJnHA7HcXs9isBhsSEUCXAhhOggAS6EEBZlqQCP9ga4rMQUQgiLBbj0wIUQ4hhLBXio3YbLESIBLoQQWCzAAWLDnBLgQgjBGQS4UsqmlPpCKfWO9/pQpdRapdRepdSrSiln/5V5jOxOL4QQxpn0wO8Hdna5/gjwv1rrEUAVcGdfFnYyEuBCCGH0KMCVUhnA5cCfvNcVcBGw1PuQxcDV/VHgiaLDHNQ0nfpM1kIIEQx62gN/HPgPoOMoUglAtda6I0kLgfTunqiUuksptV4ptb4vduWNCXPIZoRCCEEPAlwp9W9AqdZ6Q28moLVepLXO0VrnJCUl9eYljiNDKEIIYfTkWCh5wJVKqfmAC4gGfgfEKqXs3l54BlDUf2Ue03FIWXe7B7vNchvRCCFEnzltAmqtf6y1ztBaZwE3A//UWt8CrACu9z5sAfBWv1XZRechZZtlHFwIEdzOpgv7I+D7Sqm9mDHxZ/umpFPrekhZIYQIZmd0OFmt9UpgpffyfmBG35d0arI7vRBCGJYbRO4I8OrGVj9XIoQQ/mXBADc7fEoPXAgR7CwY4HJIWSGEAAsHuPTAhRDBznIB7rSHEOG0UdkgAS6ECG6WC3CApKhQyupb/F2GEEL4lSUDPDnKRVlds7/LEEIIv7JkgCdFhVJaJz1wIURws2yAl0mACyGCnGUDvK7ZTXNbu79LEUIIv7FkgCdHhQJIL1wIEdQsGeBJ3gAvlRWZQoggZukAlx64ECKYWTLAk6NcALIlihAiqFkywOMjnIQo6YELIYKbJQPcFqJIjAyltFYCXAgRvCwZ4CC70wshhGUDPDkqVLZCEUIENcsGuOyNKYQIdpYN8OQoF+X1rbR7tL9LEUIIv7BsgCdFhdLu0VTJuTGFEEHKsgHesTu9bIkihAhWlg3wzr0xZUsUIUSQsmyAd+6NWStbogghgpNlAzwh0glARYOMgQshgpNlAzzcacPlCKFSAlwIEaQsG+BKKRIiQimXMXAhRJCybICDGUapqJceuBAiOFk7wCOcMoQihAha1g7wyFAqZAhFCBGkrB3gEU7KG1rRWnanF0IEn9MGuFLKpZT6XCm1WSm1XSn1S+/tQ5VSa5VSe5VSryqlnP1f7vESIp20uj3Ut7h9PWkhhPC7nvTAW4CLtNaTgMnAXKVULvAI8L9a6xFAFXBn/5XZvYQIszemjIMLIYLRaQNcG/Xeqw7vnwYuApZ6b18MXN0vFZ5CvHdnnnLZEkUIEYR6NAaulLIppTYBpcCHwD6gWmvdMXZRCKSf5Ll3KaXWK6XWl5WV9UXNnRK9PXBZkSmECEY9CnCtdbvWejKQAcwAxvR0AlrrRVrrHK11TlJSUi/L7F7H7vQyhCKECEZntBWK1roaWAGcC8QqpezeuzKAoj6u7bTiI+R4KEKI4NWTrVCSlFKx3sthwCXATkyQX+992ALgrf4q8mRcDhuRoXbZnV4IEZTsp38IqcBipZQNE/hLtNbvKKV2AK8opX4FfAE82491npTsTi+ECFanDXCt9RZgSje378eMh/tVvOxOL4QIUpbeExOQIxIKIYKW5QM8MdIpKzGFEEHJ8gEeH+GkqqEVj0eOhyKECC6WD/CEyFDcHk1tc5u/SxFCCJ+yfIAnyu70QoggZfkA7ziglazIFEIEG8sHeGZ8GACHKhr8XIkQQviW5QM8Iy4cpz2E/JL60z9YCCECiOUD3BaiGJ4Uyd4yCXAhRHCxfIADjEiOZG+pBLgQIrgERoAnRVJU3URTa7u/SxFCCJ8JjABPjkRr2CfDKEKIIBIQAT4yJRJAhlGEEEElIAI8KyECW4iSABdCBJWACHCnPYQh8eES4EKIoBIQAQ4wPFk2JRRCBJeACfCRyZEcLG+grd3j71KEEMInAibAhydF4vZoDlc2+rsUIYTwiYAJ8CEJ4QAS4EKIoBEwAT443gR4gQS4ECJIBEyAJ0WF4nKEcLhCAlwIERwCJsCVUgyOD+eQ9MCFEEEiYAIczDCKDKEIIYJFQAV4Znw4hysb0VpOcCyECHwBFeBD4sNpbG2nokHOjymECHwBFeCDvZsSHpIVmUKIIBBYAS6bEgohgkhABXhGnOzMI4QIHgEV4C6HjUHRLglwIURQCKgABzOMIjvzCCGCQcAFeMemhEIIEehOG+BKqUyl1Aql1A6l1Hal1P3e2+OVUh8qpfK9/+P6v9zTG5oYztHaZupb3P4uRQgh+lVPeuBu4Ada63FALnCvUmocsBBYrrUeCSz3Xve7sanRAOw8UuvnSoQQon+dNsC11ke01hu9l+uAnUA6cBWw2PuwxcDV/VXkmRifHgPAtqIaP1cihBD964zGwJVSWcAUYC2QorU+4r3rKJBykufcpZRar5RaX1ZWdhal9kxyVCiJkaFsL5YeuBAisPU4wJVSkcDrwHe11selozYHH+n2ACRa60Va6xytdU5SUtJZFdvDOslOi5YeuBAi4PUowJVSDkx4v6S1fsN7c4lSKtV7fypQ2j8lnrnx6dHsLa2nua3d36UIIUS/6clWKAp4FtiptX6sy11vAwu8lxcAb/V9eb2TnRaD26PZU1Ln71KEEKLf9KQHngd8DbhIKbXJ+zcfeBi4RCmVD1zsvT4gjE8zKzJlHFwIEcjsp3uA1no1oE5y95y+LadvZMaHEeWyyzi4ECKgBdyemCArMoUQwSEgAxzg3GGJbCmqobBKdqsXQgSmgA3w66alA/D6hiI/VyKEEP0jYAM8Iy6cvOGJvLahAI9HzpEphAg8ARvgADfkZFBY1cSa/RX+LkUIIfpcQAf4ZdmDiHbZeW1Dob9LEUKIPhfQAe5y2Lhk3CBW7i6VYRQhRMAJ6AAHuGBUIlWNbWwrlk0KhRCBJeADPG9EIgCf5Jf7uRIhhOhbAR/giZGhZKdFs2pP/x/KVgghfCngAxzgglFJbDxcJadZE0IElKAI8JkjE2lr16zZJ5sTCiECR1AE+LQhcYQ5bHySL8MoQojAERQBHmq3kTssXlZkCiECSlAEOMDMkUnsL2+goFIObiWECAxBE+AXjDLn41y9V3rhQojAEDQBPjwpgrQYl2xOKIQIGEET4EopZo5M4l97y3G3e/xdjhBCnLWgCXCAmaMSqW12s0XO1COECABBFeB5wxOxhyieW30AreXgVkIIawuqAI+LcPK9S0bxzpYjLJVDzAohLC6oAhzg7lnDOXdYAg++tZ1DFQ3+LkcIIXot6ALcFqJ47KZJuD0eXvjskL/LEUKIXgu6AAdIjQnjknEpLPuiiFa3bJEihLCmoAxwgBumZVLZ0Mo/d5X4uxQhhOiVoA3wmSMTSYkOZcl6WZkphLCmoA1wuy2E66ZmsHJ3KT98bTNLNxTKeTOFEJZi93cB/nRH3lD2lNSzfFcpr20o5B/bj/LYTZOJDA3qZhFCWITy5Q4tOTk5ev369T6bXk9prfnzpwf51bs7CXPYCHfauCx7EP999Xh/lyaEECilNmitc068XbqamOOk3JE3lLGp0fxtczFF1U28uOYQF45OYs7YFH+XJ4QQ3TrtGLhS6jmlVKlSaluX2+KVUh8qpfK9/+P6t0zfyB2WwEPXTGDR13IYnhTBf72zgxZ3u7/LEkKIbvVkJeafgbkn3LYQWK61Hgks914PGE57CL+4MptDFY1c9/SnfGXRGjkMrRBiwDltgGutVwGVJ9x8FbDYe3kxcHUf1+V3M0cmcd9FI3DYQtheXMOTK/Yed//q/HKu+r/VrNkvJ0oWQvhHbzcjTNFaH/FePgoE5EDx9y8dzbJv5XFH3lA+P1hJSW0zABX1LXz31U1sLqzhlj+t5dnVB/xcqRAiGJ31duDabMZy0k1ZlFJ3KaXWK6XWl5VZcxjiikmpaA3vbT2C1pqFb2yltqmN1+4+lzljkvnvd3bIGe+FED7X2wAvUUqlAnj/l57sgVrrRVrrHK11TlJSUi8n518jkqMYMyiKd7Yc4fGP8vlwRwkPXDaK6VnxPPGVKQxLjOAny7bS1CorPIUQvtPbAH8bWOC9vAB4q2/KGbiumJTGhkNV/G55PjfmZPCN84cB4HLY+PW1EyiobOI7f/2CJ1fsZVNBtZ+rFUIEg55sRvhX4DNgtFKqUCl1J/AwcIlSKh+42Hs9oF0xMQ2nLYTLJ6TyP9dOJCREdd6XOyyBu2cNZ/muEn77wW5ufOYzPtwhB8kSQvQv2RPzDJTUNpMUGXpceHeltaayoZWv/3kd24trmTM2mcbWdo7WNFPZ0Mr10zL4zpyRsqu+EOKMnGxPTAnwflDb3MYDSzazv7yBiFA7KVGhKAUfbC8hKSqUS8elcGn2IGaNsuY6ASGEb0mADwAbD1fx1Iq9fLavgobWdv7n2gl8ZcZgf5clhBjg5FgoA8DUwXH8acF0Wt0evvnCev7zzW24HCEMjo8gOSqUzPjw077G3tJ6CqsauXB0sg8qFkIMZBLgfuC0h/DkLVO54ZnP+N6rmztvz06LZubIJMYMiqLV7aGouomESCcp0S72ltbz8Z4yPj9gdor97sUjuX/OSJTqfjweYG9pHduKapk/IRWnPWgP/S5EwJIA95PIUDuv/nsun++vxG5T7C2t592tR3h29X7a2rsf1hqZHMmP5o5hb2k9j3+UT35pPVkJ4bS0eThS20xtUxvNbe00t3moamylsKoJgHe3HuHJr04dkCGuteZgRSNZCeGnnBkJIb5MxsAHmFa3h4MVDYQ5bAyKcVHZ0MqRmmaGJkYQE+YAwOPR/Ordnby2oYCGFjdOewhpMWFEhzkIc9hwOUIID7VzztB4Glvbefj9XUzMiMGjNWEOG//vhskMTjj9cE1/c7d7ePDt7by89jDfuWgEP7h0tL9LEmJAkpWYAarj8ztV7/WltYf4w8f7GRwfztaiGmwhigf/bRypMS5GpUQRF+E87XSaWttpbfd0zkTOVsfxZD7JL2d0ShS7S+p4+papzJuQetzjiqrNUkR6bFifTFcIK5IAFwDsL6vn639ex8GKRgCcthAuyU7h/jkjGZUS1fm4do9ma1ENn+wpY/XecjYerkJruDQ7helZ8TS1tdPY0k5jazuNre7O/63tmvTYMMalRnHl5HRiwhzUNLWx+2gdR2qaaHF7aHV7+N3yfGoa2/ivq7K5Zmo6N/1hDbuO1nL5hDQuGZfM2NRoVu4u49fv7SQi1M7b384jLSaMJesL+Pv2o2wprGHe+EH84NLRxEc4OVrTzP9+uIc1BypIjgolLtyJ3aa4ZFwK10zJOKs2K6tr4Zd/286tuUPIHZbQub1/QmToWb1uV698fpjYcCdzxw/qs9cUgUMCXHRqbmtnT0kdNU1trNhVxusbzQmdF92Wg9aalz4/zOr8cmqa2gCzcvX8EYm4PZrXNxZS3WhuD1EQ4bQT5rQREWonzGHDblMcrmykurGNCKeNsanRbCqoxn3CCaNHp0Tx+M2TGZsaDUBpXTMPv7+LD3eUUNfs7nzczJGJbCqoJj02jPTYMJbvKmVYYgSjUqL4cGcJTlsIseEOKhpaQcOFo5OobW6jurGNumY3RdVN/NdV2dx2btYp26ShxcyEkqKOD+X6Fjc3L/qMbUW1uBwhPHLdRF5bX8i/9pVz8/TBfO+SkQCEO+3H7aDl8Wg2FVaTEOEkPTaMT/LL+XBnCcXVTUS5HPzq6vGdSzObC6q5+ql/oTX88LLRfOvC4adcotpSWM2S9QUcKG+guc1DbJiDr54zeMCfPaquuY3Fnx6ktK6FMIeNG3IyGZEcSVVDK+9vO4rb4yErIYILZP+IL5EAFydVXN3Eguc+J7+0HoCECCcXjUlm5qgk8oYnHNfTbHV7qG9xE+60EWoPOWnQbCuq4dnVB9hbWs/5IxOZMTSejNgwXA4bLW4PQxLCcdi+vFK11e1hW3EN+SV1RIY6mD9hEKvyy7nj+c87h35uzR2CUoo9JXX8Zc0hmlrbiXI5uCMv67hNMVvdHu59eSMf7ijh1tzB3JiTSUltC5/tqyC/tI7KhlZmjUoiPsLJUyv3UdPUxldnDGb+hFQKqxo5XNnIqj1lbCuu5eFrJ7Bo1X7yS+sJd9qYMzaF97Yeod07Y7KHKKYOiWN0ShQazYpdZZ3DP05bCK3tHqJcdoYkhLP7aB3nDE3g+TumY1OK6575lILKJs4bnsDbm4u5e9ZwFs4b0227Hixv4Mr/W027RzMyJYpwp41DFY2U1DbzzK3TuHhcCg0tblbtKWNTYTUZsWFkxocTohRx4U7GpUUTomBfWT3bimrZX97AlMxYLhyddNYrkWua2gi1h+By2AAzE/vd8nzWH6pkSEIEH+4ooayuhdhwBw0tbuwhIdyRl8WS9QWU17d2vk53Q2n9YUthNe9uPcJl2YOYkhk7oFeiS4CLU6pubOU3H+xmYnoMV09J7/wRDhSf5JcRH+EkOy3mjJ7X6vbw4FvbeGNjEa3tHgBcjhBGpUQR5rCx7mAlHg3nDktgaFIEr64r6AxlW4giPTaM710ykmumZFBW18LiTw9yY04mgxPC2XmkllV7yggPtXOkuomP95RxpKYZd7uHCRkxXD8tg8bWdvJL6skdlsBFY5Jx2kNYuqGQB17bzMyRiaREu1i6oZBHb5jEtVPS+dlb23hp7WF+Mn8MHg1vbCzkOxeN5IpJadQ2t3HdU59SXt/C298+v3NmVdfcxq1/WsvOI3Wkx4VxuLKRdo/GFqI630uH+AgnDpuipLbluNsnZsQwOiUKuy2EtBgXmfHhZMaHEeVyUFTdxMZDVSzfWUpsuINvzx7Red5YpRRJkaHsPFLbOcNKiHCy4LwsDpY38MYXRYxMjqS4uonRg6L4+RXZTMqMpaS2mftf+YI1+yvJTovmoWsmkBbr4psvbGB/aT3v3jezVyva95bW8eGOUoqrmyiqbqK4ugmtIcpl596LRjDbu//EhkNVLHjuc+pbzNLe8KQIvn7+UGZkxVNW18KOI7XsPFLHBaMSuXJSGo2t7WwqqGZyZiwRXZa0mlrbKagyS5wjkyN7tD6pNyTARVCrbGhl+c4S0uPCmDYkjlC7mUGV1bVwtKaZ8enRKKU4UN7A4cpGhsSHkx4X1u1SQl/4w8f7WLRqP5WNrUwfEs8rd+US4g3cu/+yofNgaCnRoZTUtnQOJTW2tvPinTM4b3jica9X3djKg29tx+3xMDwpkrwRiUwbEkdZXQvF3mAt8s5kWt0ezh+RyNQhcWTEhfH2pmL+/OlBapvaaHF7zHDUCUIU5GTFc6iioTP8xwyKIiHSSUltC6NSIpmUEYvbo03Y7zJHmH7g0lHcO3sE8OUV7e0ezbqDlUwbEtfZzgWVjVz+xCd4NKTGuIiLcBIf7iQ6zI7LYWNvaT27jtaRlRDO6EFR7CtroLHVzU/mjcVhD+GO59dR3+ImJsxBWmwYaTEu7DbFnpJ6Dlc28vMrxlHX7ObplftIigpl0dem8cXhal5cc4itRTXH1RflslPX7Gbq4Fj2ltZT22yWPM8fkYjDHsKR6ia2FtV0bvabGBnKswtymJQZe9zrlNY189GOUm6ennnS4yidjrUDvK0JaoshYXjfFyWEH7nbPYQoddwPu6m1nSdX7OW8EQlMz4rnN3/fxcnvLK8AABF5SURBVBsbi5g1KomvnTuEKYP79xzizW3tFFY1UlDZRG1zGxlxYYxIiiIm3EFzWztvbyomKSr0lMMu24trKKtr6dUewxsPV/Ha+kKqG1upbDB/dc1uGlvdDEmIYMygKPaXN7C3tJ5hSRFUNrRyqKIRpz2EjLgwXvj6DDLiju+917e4ueuF9Xy6z5wC8bzhCTx242QGxbgAszXXhkNVFFU3kRQVyojkSBIiQnnhs4P8cdV+pgyO4/KJqXySX8aa/ZWEKIgLd5KTFc+4tGicthB+9e4OyutbuH5aBoPjwymra2FLYU3nUt7b385jYkbsiW+3R6wd4M/Ph9Z6uOtjGMDjVEII32tqbeeRv+9i19Fafv+VqV9aEd2hua2dd7YcYXpWHEMSIvq8jvL6Fv5j6RbWHaikrsVNqD2EEcmRzBmTzBWT0hjZZSuvM2XtAP/8j/DeA/DNf0L6tL4vTAgh+ojWmtpmN5Ghdmy9HDI50ckCfODtW92diTeBIwLWPefvSoQQ4pSUUsSEOfosvE/FGgHuioaJN8C216Gpyt/VCCHEgGCNAAfI+Tq4m+DzP/m7EiGEGBCsE+Cpk2D4HFjxK3jjLumJCyGCnnUCHOArr8CsH5mhlGcvhapD/q5ICCH8xloBbnfC7J/AbW9DfQn86WIo/sLfVQkhhF9YK8A7ZOXB1/8B9lB4/nLY8wE010BLvb8rE0IIn7FmgAMkj4FvfGT2znz5Rnh4MPxmKGx8wd+VCSGET1j7lGpRg+CO92Dji6A9sPcjePs7ULwJzvs2xA/zd4VCCNFvrLEnZk+1u+EfP4W1fwA0JI+DxFEQngAhNph6Gwya0H/TF0KIfnCyPTGt3QM/kc0O8x6B874DW1+DQ5/B0S3Hxsfz/wH3rgObAw79C2yhEJsJrQ0QYoe4If5+B0II0WOBFeAdYjLg/O+Zvw75H8FL18H650ygr/z1l5834hIYMx/K90JDmem1xw+HUZdCWLw5oFZ0utkztCc8Hti6BDLPgfihffPehBDCK7CGUE5Fa3jhKihcD20NMOFGGH8t1BRCaBRUF8DaZ6CxHOxhEJViArimADihjZLGws0vmRWoRRvM3qFRKWbIZtRl4IqBtmZY9u+w401wxcJNL0LiaKjcDy11pobWRogdDENndl+zp93MRDq4W82mlF3VlZitccK8h6n0eCDEuuumhRBfZu2jEfaV4k2w6EIYkgdfW/blMOw47nhc1rHgrC+Fff8Edws4I6DqAHzyGIy9Aq75A/zxIijZZlaietxgc5qVp01VZlv1mQ/ArnegbFf3Ndmc8EC+CeC374NDn0JEonlu1UGIG2r2Qj2yyYR/0hhIHmvCvGIvlO8GR7g51EBrPWx5DSbdDPMfPRbkWpva2tvMf48bjm6F3e+Z58QOMTOSjr+oVEAB+vgZSGsD7HrXzNRcMRCVZt6r9pilGu0BuwtSJ5phKjAzlD3vm5nMiIu7b4N2txn+6vo5aG2ec9z0G+HgagiLM9Own+Kkwu1uqDti3mt4vKn3RG3N5jW6O0RxSx2oEPOZ94TW5rvjioHQyOPv627GO5B52qGh3HRKxIAQHGPgp5M2Ge75lwnF7n5QjrAvnzQiMtkEYldN1bDmaUjPgeKNcOXvYfItpje+/U2oOWzG18dfZ4Zk8u6DtYtMTz9xhOmRO8Kh+jD89SYTpFnnw8bFJqxViFnZOu4qKN0JBWshZTyMu9oE75HN5uiMcUNgyi1Qsh3WPGVmBhnTYf2zZklChcDuv5tjyHTHHmaGg+pLTrjDG96h0XDjCzDsQvjX47DqURP4p+OKhWGzzPOLNkLpdnBGwvd3mv+v32nCLiIRyvOhfI85THDGdNi/Esp2mtcJcZj3GJFk3kvxJrPkAmZGMWw2DJ9tZmylO73rOurMX2MF6PZjNaXnwMwfQP1R0yZHNpvLjnBIGAG595gatr4G+R+adSfaA5Ep5vsSN8TMANsazftyRkBLrfkuNFVB9SEzzcxz4OsfmED/+BEz8y7ZZl5jSB4MOc/MhOuOmKW/mgIzneh007Zlu017VOwDd7OZuYRGmRmDK9Y8bsQcM6Mt2WbasaXOzHTTp5rvwsF/mZlW1CCzt3JDmVnXk5kLM+4yM8Xd75vvblO1mV55vukYpE40ezpXH4axV8J595nvT32p+Z4Ub4LDn8Gkr8BFPzUz6Px/wKDxZugSzGex+n/hyBZIGmVqc7eYzzFtMqRONrft/cj8zfoRRCSYme6+5VC4ziwRqxDTsYnLMn8xmab9646aDoI91KzbqjoAe5ebNk2dDBk55rNsqYOCz01bjZ5nOjx7l8PRzVC2x3z+Ghh+ofnc7C7TVke3ms9UeyDvuzB6rpmpHVxtXhPM76a5BvatMJ+BI8zUq9shbYppH1eMeb36UjNDHDrTPK4PBVcPvK/UFsPvJkF7q+m9fmfDsR7nmdAaHp9ofjiZ0+Gfv4L7N5sv65mqO2q+gGGxsOq35rXC4iD7GohINj3cELsJRZvDBMHwi8AZbnqiNYUmhKoPm/cXYjfDP1UHYfR82LYURl9uNs9Mm2J++LVFUHnABIIrxvxvqjI7Vh3+zPxowxPN0srKX8O830J0Grx6i5lRtTWZYEscCQc/MT+cIXkw9AJTY3ONCefGSvNjShxlXqu1wayE3vkO1BaaEE4eZ0IrNNoEXniCCRSbE+qKYcNi73AYZqkhM/fYktKBVVCy1dynQmDwuaYOe6gJh8oDJlDsTvMDbK41NbhiTHuHxZlAUsrsh3DTX8zn8d4DMOR889mW55uaTzyGj937w29rAJSZUSSOgoSR5rPRHhNSzdWmPcp2m5o6hMWZ91tbbJY2VIhp25Y6M7wWOxgik8znWrkfMmaYIN39rpmeK9q0Q8IIs1dzxV5Tc/oUWPesCcyuIpLMTK1kO9z5oVk6Xflr81qDJpj3V1NgOhhDzoOKfGisMp9nk/dzBPOZdbx27r0w99fw7gOw7o+gbOb7iTYzxRNr6E7iaNN2xZugobSbB3g7JSjzfpPHmmm0NZoZdv3RY49LGGFmfjUF5nP82jLTYdv59pdf1hlpvsNtjeb1tcf8Zjqn18W9n0PS6NO/l+6q748hFKXUXOB3gA34k9b64VM9PmACHOBv98OGP8OV/wdTv9b71/nHz8yXIyrV9JLueK9v6ivdZVacnmqY4XTqS+F5b8/lnLvhsv/p/fj6otmmh2l3mf/3rjt+2AS+PJRyOh3rKKLTT/88d6vpKcZlQUr28cMmWpv7qg6ZGUR0L8+I3u6Gp881PfWGMsicAbe+cWxaHo8ZSqvcb6YRM9gshYAJaLurZz208r1mCSt57LGhobYmE6pxQ01vtjtbl8I73zMz1ot+aoLzxHZrqTMzBIDaI1CwxswMI1NMeIfFmcc8lWvCqu6IWdJMGmNmwlGpZmY69TYzQ+2qtQGObjPDgWW7zExyz9/NjPjWpbD4Spj8VZj3GzPzAvPZNJSZz6b6kAnMyGQzbXeLGa6KTDGB2/H4mgKzNOwINz3rsl2mU5E4yqyjOrEuj8e0f3uree8dw2YN5WaItNp7zKWLf2EOqIc2M1ObE9KmfnlpvmyP6fwoZTpPEUnmb9D4XvfA+zzAlVI2YA9wCVAIrAO+orXecbLnBFSA15fB5pch91u96313KNpgviRw9jOD/lBfamocNffsTme36WV48x5z+aqnzNBPINr5N3j1VtMD/dZnA2/T1LoS75Jj5tm9zp4PzB7Q6dPg9vfA4erd65Tnw/9NNzOvEDvcv+nYTG0gKNsNy+42v/OJN/itjP4I8HOBX2itL/Ne/zGA1vp/TvacgArwvqI1/G6imSE8sKfnmyhaTVsTPDbOvL9vrz+7md5ApjW8/x9mGGb8tf6upn/t/9gMm5zYoz1TS+80Q3RzHjTrKcSX9MdKzHSgoMv1QuCcbiZ8F3AXwODBg89icgFKKZj7iBnrC9TwBrPo+NUlZtE4UMMbzOc5/7f+rsI3hs3qm9e5+OdmCCT3W33zekGk37dC0VovAhaB6YH39/Qsacx8f1fgG5nT/V2BGIhiB8NlD/m7Cks6mz0+ioCuA2kZ3tuEEEL4wNkE+DpgpFJqqFLKCdwMdLOdjRBCiP7Q6yEUrbVbKfVt4APMZoTPaa2391llQgghTumsxsC11u8BfbThshBCiDMhRz0SQgiLkgAXQgiLkgAXQgiLkgAXQgiL8unRCJVSZcChXj49ESjvw3L6wkCsCQZmXVJTzw3EuqSmnuuPuoZorZNOvNGnAX42lFLruzsWgD8NxJpgYNYlNfXcQKxLauo5X9YlQyhCCGFREuBCCGFRVgrwRf4uoBsDsSYYmHVJTT03EOuSmnrOZ3VZZgxcCCHE8azUAxdCCNGFBLgQQliUJQJcKTVXKbVbKbVXKbXQTzVkKqVWKKV2KKW2K6Xu994er5T6UCmV7/0f54fabEqpL5RS73ivD1VKrfW216vew/36uqZYpdRSpdQupdROpdS5/m4rpdT3vJ/dNqXUX5VSLl+3lVLqOaVUqVJqW5fbum0XZTzhrW2LUmqqj+v6rffz26KUWqaUiu1y34+9de1WSl3mq5q63PcDpZRWSiV6r/ukrU5Wk1LqO9622q6U+k2X2/u3nbTWA/oPc6jafcAwwAlsBsb5oY5UYKr3chTmhM7jgN8AC723LwQe8UNt3wdeBt7xXl8C3Oy9/Axwjx9qWgx8w3vZCcT6s60wpwA8AIR1aaPbfd1WwAXAVGBbl9u6bRdgPvA+oIBcYK2P67oUsHsvP9KlrnHe32EoMNT7+7T5oibv7ZmYw1gfAhJ92VYnaafZwEdAqPd6sq/aqV9/NH3UYOcCH3S5/mPgxwOgrreAS4DdQKr3tlRgt4/ryACWAxcB73i/wOVdfnjHtZ+PaorxhqU64Xa/tRXHzuEajzmM8jvAZf5oKyDrhADotl2APwBf6e5xvqjrhPuuAV7yXj7uN+gN03N9VROwFJgEHOwS4D5rq24+vyXAxd08rt/byQpDKN2dPDndT7UAoJTKAqYAa4EUrfUR711HgRQfl/M48B+Ax3s9AajWWru91/3RXkOBMuB579DOn5RSEfixrbTWRcCjwGHgCFADbMD/bQUnb5eB9N3/OqaHC36sSyl1FVCktd58wl3+bKtRwEzvUNzHSqmOk7/2e01WCPABRSkVCbwOfFdrXdv1Pm1msz7bLlMp9W9AqdZ6g6+m2UN2zGLm01rrKUADZmigkx/aKg64CjNzSQMigLm+mn5P+bpdekIp9VPADbzk5zrCgZ8AD/qzjm7YMUt2ucAPgSVKKeWLCVshwAfMyZOVUg5MeL+ktX7De3OJUirVe38qUOrDkvKAK5VSB4FXMMMovwNilVIdZ1vyR3sVAoVa67Xe60sxge7PtroYOKC1LtNatwFvYNrP320FJ28Xv3/3lVK3A/8G3OKdufizruGYGfBm73c+A9iolBrkx5rAfN/f0MbnmKXhRF/UZIUAHxAnT/bOUZ8FdmqtH+ty19vAAu/lBZixcZ/QWv9Ya52htc7CtMs/tda3ACuA6/1Rk7euo0CBUmq096Y5wA782FaYoZNcpVS497PsqMmvbeV1snZ5G7jNu4VFLlDTZail3yml5mKG567UWjeeUO/NSqlQpdRQYCTweX/Xo7XeqrVO1lpneb/zhZgNC47i37Z6E7MiE6XUKMxK+3J80U79McjfDysN5mO2+tgH/NRPNZyPWbTdAmzy/s3HjDkvB/Ixa6Lj/VTfhRzbCmWY94uyF3gN79pxH9czGVjvba83gTh/txXwS2AXsA14EbN1gE/bCvgrZgy+DRNAd56sXTArpJ/0fu+3Ajk+rmsvZgy34/v+TJfH/9Rb125gnq9qOuH+gxxbiemTtjpJOzmBv3i/VxuBi3zVTrIrvRBCWJQVhlCEEEJ0QwJcCCEsSgJcCCEsSgJcCCEsSgJcCCEsSgJcCCEsSgJcCCEs6v8DXEDPDV3Jq9gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMb8Zvq5aIN4",
        "outputId": "92d81bf1-e6ae-4c61-b3c5-b804b52c7ef6"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "top_k=3\n",
        "\n",
        "def process_image(image):\n",
        "    '''takes in a PIL Image & transforms it to allow a forward pass'''\n",
        "    image = image.resize((256,256))\n",
        "    image = image.crop((0,0,224,224))\n",
        "    np_image = np.array(image)\n",
        "    np_image = np_image / 255\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    pil_image = (np_image - mean) / std\n",
        "    return pil_image\n",
        "\n",
        "#Define PIL image & run it with process_image() to get predictions\n",
        "image = Image.open('/content/drive/My Drive/Projects/wtFlower/test_me.jpg')\n",
        "processed_img = process_image(image)    \n",
        "\n",
        "#Creating a Dataframe that contains Labels & Indices of Classes (df_combined)\n",
        "pd_class_to_idx = pd.Series(model.class_to_idx)\n",
        "pd_cat_to_name = pd.Series(cat_to_name)\n",
        "\n",
        "#choosing column indices\n",
        "columns = {'Index' : pd_class_to_idx,\n",
        "            'Label': pd_cat_to_name}\n",
        "\n",
        "#combining series to one dataframe\n",
        "df_combined = pd.DataFrame(columns)\n",
        "\n",
        "#Predicting top kk with predict()\n",
        "topk_ps, topk_cs = predict(processed_img, model)\n",
        "\n",
        "#itterating trough the top kk classes & translating it to legible strings from df_combined\n",
        "comb_classes = []\n",
        "\n",
        "for i in topk_cs:\n",
        "    comb_class = df_combined.values[i]\n",
        "    comb_classes.append(comb_class)\n",
        "\n",
        "flower_name = comb_classes[0][1]\n",
        "#class_probability = np.linalg.norm(topk_ps[0])\n",
        "\n",
        "print('flower name:', flower_name)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flower name: rose\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZxBFJ1k781a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}